{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.utils import SerializableLock\n",
    "from datetime import datetime, timedelta\n",
    "from floater.generators import FloatSet\n",
    "import bcolz, os, re\n",
    "import dask.array as dsa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '/data/scratch/cz2397/traj_0090-0180.bcolz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = FloatSet(xlim=(0, 360), ylim=(-80, 70), dx=0.03125, dy=0.03125)\n",
    "Npart = fs.Nx*fs.Ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bcolz_to_arrays(bc, time, npart_range, fields, lock=None, dtype='f8'):\n",
    "\n",
    "    \"\"\"Convert bcolz data from a certain timestep to a 2d numpy array.\n",
    "    For some reason, this is fast.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bc : bcolz ctable\n",
    "        where the data lives\n",
    "    time : float\n",
    "        the timestep value\n",
    "    fields : list of strings\n",
    "        which fields to extract\n",
    "    fs : FloatSet\n",
    "        needed to reshape the array properly\n",
    "    dtype : numpy.dtype\n",
    "        data type to which to coerce the output data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    d\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(\"Called bcolz_to_dataframe(%g) on %s\" % (time, bc.rootdir))\n",
    "    npart_min, npart_max = npart_range\n",
    "    npart = np.arange(npart_min, npart_max)\n",
    "    query = \"(time==%g) & (npart>=%g) & (npart<%g)\" % (time, npart_min, npart_max)\n",
    "    \n",
    "    # convert to pandas dataframe\n",
    "    if lock is not None:\n",
    "        lock.acquire()\n",
    "    df = pd.DataFrame(bc[query])\n",
    "    if lock is not None:\n",
    "        lock.release()\n",
    "        \n",
    "    # reindex the dataframe\n",
    "    df = df.set_index('npart', drop=True, verify_integrity=True)\n",
    "    df = df.reindex(npart)\n",
    "    \n",
    "    data = df[fields].values\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bcolz_to_dataset(fname, num_floats, fields=['x', 'y', 'vort'],\n",
    "                     delta_t=86400, date0=datetime(1993,1,1)):\n",
    "    \n",
    "    datadir = os.path.dirname(fname)\n",
    "    basename = os.path.splitext(os.path.basename(fname))[0]\n",
    "\n",
    "    # figure out time range from basename\n",
    "    day0, day1 = [int(day) for day in re.search('traj_(\\d+)-(\\d+)', basename).groups()]\n",
    "    days = np.arange(day1-day0)\n",
    "    times = delta_t * days\n",
    "    refdate = date0 + timedelta(days=day0)\n",
    "    \n",
    "    bc = bcolz.open(rootdir=fname, mode='r')\n",
    "\n",
    "    nt = len(times)\n",
    "    npart = np.arange(1,num_floats+1)\n",
    "    # get the full particle range at each timestep\n",
    "    npart_range = npart[0], npart[-1]+1\n",
    "    lock = SerializableLock()\n",
    "    dtype = 'f8'\n",
    "    data = [dsa.from_delayed(\n",
    "                delayed(bcolz_to_arrays)(\n",
    "                    bc, time, npart_range, fields, lock=lock, dtype=dtype),\n",
    "                (num_floats, len(fields)), dtype)\n",
    "            for time in times]\n",
    "    stacked_data = dsa.stack(data)\n",
    "    \n",
    "    # create xarray dataset\n",
    "    data_variables = {field: (('time', 'npart'), stacked_data[...,n])\n",
    "                      for n, field in enumerate(fields)}\n",
    "    ds = xr.Dataset(data_variables, {'npart': npart, 'time': days})\n",
    "    ds.time.attrs['units'] = 'days since %s' % date0.strftime('%Y-%m-%d')\n",
    "    \n",
    "    outfile = os.path.join(datadir, basename + '.nc')\n",
    "    with ProgressBar():\n",
    "        ds.to_netcdf(outfile, engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[                                        ] | 0% Completed |  0.0s"
     ]
    }
   ],
   "source": [
    "bcolz_to_dataset(fname=fname, num_floats=Npart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
